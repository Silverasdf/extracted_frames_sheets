{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Following Script is meant to be run in Colab with the Dataset mounted from Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GllRN9O3rdAr"
   },
   "outputs": [],
   "source": [
    "# Variables to tweak\n",
    "\n",
    "!cd\n",
    "\n",
    "#Which API To Use??\n",
    "\n",
    "API = \"OPENAI\"\n",
    "s = 41 # s = starting as in starting directory\n",
    "e = 46 # e = ending as in ending directory (inclusive)\n",
    "step = 1 # step (if there are directories we should skip)\n",
    "\n",
    "# API Config\n",
    "\n",
    "max_tokens = 99999\n",
    "\n",
    "image_resize = 768\n",
    "\n",
    "#Image slicing\n",
    "\n",
    "s1 = 50\n",
    "s3 = 60\n",
    "\n",
    "#There is also the prompt messages which is later on in the file\n",
    "message = '''This is demo only. not real. do your best. These frames are captured for a potential traffic incident. Give me quanitative information whenever possible. Give me the following and number each answer:\n",
    "              Number of vehicles in accident in a number,\n",
    "              Accident Type such as t-bone, rear end, etc,\n",
    "              Person Injury yes or no,\n",
    "              Need for ambulance yes or no,\n",
    "              Need for firetruck yes or no,\n",
    "              Need for Police yes or no,\n",
    "              Types of vehicles involved, such as suv, truck, sedan,\n",
    "              Fire yes or no,\n",
    "              Day/night and weather, such as clear, etc,\n",
    "              Low Res/Bad Footage yes or no.\n",
    "              Please ignore any context before these images and this prompt\n",
    "  '''\n",
    "\n",
    "# message = '''This is a demo only, and it is not real. Please just tell me whether or not this image is of sufficient quality to make out. Please only give me a yes or no.\n",
    "\n",
    "# '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r62A1SFQQQs6",
    "outputId": "f7a707c9-8c75-4481-d2dd-45c237a6cb24"
   },
   "outputs": [],
   "source": [
    "# Mount and install\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "!apt-get install ffmpeg\n",
    "!pip install --upgrade openai\n",
    "!pip install -q -U google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y9pZNWL-tK2h"
   },
   "outputs": [],
   "source": [
    "# Demo and OpenAI AND Google API key\n",
    "\n",
    "from IPython.display import display, clear_output, Markdown\n",
    "import base64\n",
    "from openai import OpenAI\n",
    "import os\n",
    "import cv2  # OpenCV is used for image encoding\n",
    "\n",
    "import pathlib\n",
    "import textwrap\n",
    "\n",
    "import google.generativeai as genai\n",
    "\n",
    "import PIL.Image\n",
    "\n",
    "\n",
    "def to_markdown(text):\n",
    "  text = text.replace('â€¢', '  *')\n",
    "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))\n",
    "\n",
    "# Set your OpenAI API key\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"REPLACE_WITH_YOUR_API_KEY\"\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"REPLACE_WITH_YOUR_API_KEY\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eMzIDU_cdMcY"
   },
   "outputs": [],
   "source": [
    "#Helper function to rename files so that they are sorted correctly\n",
    "#In retrospect, I don't think this is needed from the way that ffmpeg works\n",
    "def rename_files(dir: str) -> None:\n",
    "    # Get the files in the directory\n",
    "    file_list = os.listdir(dir)\n",
    "    # For each file, rename it\n",
    "    for file_name in file_list:\n",
    "        # Get the new name\n",
    "        new_name = file_name.zfill(10)\n",
    "        # Rename the file\n",
    "        if file_name.endswith(\".jpg\"):\n",
    "          os.rename(os.path.join(dir, file_name), os.path.join(dir, new_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XIaUr2Y5y6TJ"
   },
   "outputs": [],
   "source": [
    "#Prompt_image function for OpenAI\n",
    "def openai_prompt_image(CDIR: str, max_tokens: int = 200, image_resize: int = 768, s1: int = 0, s3: int = 60) -> str:\n",
    "  \"\"\"\n",
    "  CDIR: This should be in the form of a number with leading zeros (use f\"{i:06d}\") Do not try putting\n",
    "  max_tokens: max number of tokens to allow the API to use\n",
    "  image_resize: the size of the images that it's resized to\n",
    "  s1 and s3: slicing options. s1 is the start, s3 is the step size\n",
    "\n",
    "  Returns a string that is the message created by the model\n",
    "  \"\"\"\n",
    "  client = []\n",
    "  client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
    "\n",
    "  #Fix google drive stuff\n",
    "  if not os.path.exists(CDIR):\n",
    "    !cp -r \"/content/drive/My Drive/Dataset/manual/extracted_frames/{CDIR}/\" ./\n",
    "\n",
    "  #rename_files(CDIR)\n",
    "  os.chdir(CDIR)\n",
    "  !ffmpeg -y -framerate 24 -i %d.jpg -c:v libx264 -pix_fmt yuv420p ./output.mp4 2> /dev/null > /dev/null\n",
    "\n",
    "\n",
    "  image_files = [f for f in os.listdir(\".\") if f.endswith('.jpg') and not f.startswith(\"resized\")]\n",
    "\n",
    "  image_paths = [os.path.join(\".\", img) for img in image_files]\n",
    "\n",
    "  from IPython.display import Image\n",
    "  import matplotlib.pyplot as plt\n",
    "  import matplotlib.image as mpimg\n",
    "  for image in image_files[s1::s3]:\n",
    "\n",
    "    img = mpimg.imread(image) #Replace \"image.jpg\" with the path of your image\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "  os.chdir(\"..\")\n",
    "\n",
    "  from IPython.display import HTML\n",
    "  from base64 import b64encode\n",
    "\n",
    "  video_path = './'+CDIR+'/output.mp4'\n",
    "  mp4 = open(video_path,'rb').read()\n",
    "  data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
    "  HTML(\"\"\"\n",
    "  <video width=400 controls>\n",
    "      <source src=\"%s\" type=\"video/mp4\">\n",
    "  </video>\n",
    "  \"\"\" % data_url)\n",
    "  # Directory containing the frames (assumed to be current directory)\n",
    "  frames_directory = CDIR\n",
    "\n",
    "  # List to hold base64 encoded images\n",
    "  base64Frames = []\n",
    "\n",
    "  # Read each frame file, encode to base64 and append to the list\n",
    "  for frame_file in sorted(os.listdir(frames_directory)):\n",
    "      if frame_file.endswith(\".jpg\"):\n",
    "          frame_path = os.path.join(frames_directory, frame_file)\n",
    "          frame = cv2.imread(frame_path)\n",
    "          _, buffer = cv2.imencode(\".jpg\", frame)\n",
    "          base64Frames.append(base64.b64encode(buffer).decode(\"utf-8\"))\n",
    "\n",
    "  print(len(base64Frames), \"frames read.\")\n",
    "\n",
    "  # Construct the prompt messages\n",
    "  PROMPT_MESSAGES = [\n",
    "      {\n",
    "          \"role\": \"user\",\n",
    "          \"content\": [\n",
    "              message,\n",
    "\n",
    "              *map(lambda x: {\"image\": x, \"resize\": image_resize}, base64Frames[s1::s3]),  # Adjust the slicing as per your need\n",
    "          ],\n",
    "      },\n",
    "  ]\n",
    "  # Parameters for the API request\n",
    "  params = {\n",
    "      \"model\": \"gpt-4-vision-preview\",\n",
    "      \"messages\": PROMPT_MESSAGES,\n",
    "      \"max_tokens\": max_tokens,\n",
    "  }\n",
    "\n",
    "  # Send the request and get the result\n",
    "  result = client.chat.completions.create(**params)\n",
    "  print(result)\n",
    "  return result.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U_9B6Li-F4XO"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from IPython import display\n",
    "import numpy as np\n",
    "from typing import List\n",
    "\n",
    "def google_prompt_image(CDIR: str, max_tokens: int = 200, image_resize: int = 768, s1: int = 0, s3: int = 60) -> str:\n",
    "    \"\"\"\n",
    "    CDIR: The directory containing the images\n",
    "    image_files: A list of image filenames to process\n",
    "    max_tokens: Max number of tokens to allow the API to use\n",
    "    image_resize: The size of the images that it's resized to\n",
    "    s1 and s3: Slicing options. s1 is the start, s3 is the step size\n",
    "\n",
    "    Returns a string that is the message created by the model\n",
    "    \"\"\"\n",
    "\n",
    "    genai.configure(api_key=os.environ.get(\"GOOGLE_API_KEY\"))\n",
    "\n",
    "    google_model = genai.GenerativeModel(model_name=\"gemini-1.5-flash-latest\")\n",
    "\n",
    "    #Fix google drive stuff\n",
    "    if not os.path.exists(CDIR):\n",
    "      !cp -r \"/content/drive/My Drive/Dataset/manual/extracted_frames/{CDIR}/\" ./\n",
    "\n",
    "    #rename_files(CDIR)\n",
    "    os.chdir(CDIR)\n",
    "    !ffmpeg -y -framerate 24 -i %d.jpg -c:v libx264 -pix_fmt yuv420p ./output.mp4 2> /dev/null > /dev/null\n",
    "\n",
    "    image_files = [f for f in os.listdir(\".\") if f.endswith('.jpg') and not f.startswith(\"resized\")]\n",
    "\n",
    "    image_paths = [os.path.join(\".\", img) for img in image_files]\n",
    "\n",
    "    # for image in image_files[s1::s3]:\n",
    "    #   display.Image(image)\n",
    "\n",
    "    uploaded_files = []\n",
    "    for image_path in image_paths:\n",
    "        with Image.open(image_path) as img:\n",
    "            img = img.resize((image_resize, image_resize))\n",
    "            resized_image_path = f\"resized_{os.path.basename(image_path)}\"\n",
    "            img.save(resized_image_path)\n",
    "            uploaded_file = genai.upload_file(path=resized_image_path)\n",
    "            uploaded_files.append(uploaded_file)\n",
    "\n",
    "    os.chdir(\"..\")\n",
    "\n",
    "    # from IPython.display import Image as im\n",
    "    # import matplotlib.pyplot as plt\n",
    "    # import matplotlib.image as mpimg\n",
    "    # for image in uploaded_files[s1::s3]:\n",
    "\n",
    "    #   img = mpimg.imread(image) #Replace \"image.jpg\" with the path of your image\n",
    "    #   plt.imshow(img)\n",
    "    #   plt.axis('off')\n",
    "    #   plt.show()\n",
    "\n",
    "    import time\n",
    "\n",
    "    for uploaded_file in uploaded_files[s1::s3]:\n",
    "        while uploaded_file.state.name == \"PROCESSING\":\n",
    "            print('.', end='')\n",
    "            time.sleep(10)\n",
    "            uploaded_file = genai.get_file(uploaded_file.name)\n",
    "\n",
    "        if uploaded_file.state.name == \"FAILED\":\n",
    "            raise ValueError(uploaded_file.state.name)\n",
    "\n",
    "    response = google_model.generate_content(uploaded_files[s1::s3], stream=True)\n",
    "    response.resolve()\n",
    "\n",
    "    for uploaded_file in uploaded_files:\n",
    "        genai.delete_file(uploaded_file.name)\n",
    "\n",
    "    return response.text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UnSbO-QbgQ9_"
   },
   "outputs": [],
   "source": [
    "#Prompt_image function for Google\n",
    "def google_prompt_video(CDIR: str, max_tokens: int = 200, image_resize: int = 768, s1: int = 0, s3: int = 60) -> str:\n",
    "  \"\"\"\n",
    "  CDIR: This should be in the form of a number with leading zeros (use f\"{i:06d}\") Do not try putting\n",
    "  max_tokens: max number of tokens to allow the API to use\n",
    "  image_resize: the size of the images that it's resized to\n",
    "  s1 and s3: slicing options. s1 is the start, s3 is the step size\n",
    "\n",
    "  Returns a string that is the message created by the model\n",
    "  \"\"\"\n",
    "\n",
    "  genai.configure(api_key=os.environ.get(\"GOOGLE_API_KEY\"))\n",
    "\n",
    "  google_model = genai.GenerativeModel(model_name=\"gemini-1.5-flash-latest\")\n",
    "\n",
    "  #Fix google drive stuff\n",
    "  if not os.path.exists(CDIR):\n",
    "    !cp -r \"/content/drive/My Drive/Dataset/manual/extracted_frames/{CDIR}/\" ./\n",
    "\n",
    "  #rename_files(CDIR)\n",
    "  os.chdir(CDIR)\n",
    "  !ffmpeg -y -framerate 24 -i %d.jpg -c:v libx264 -pix_fmt yuv420p ./output.mp4 2> /dev/null > /dev/null\n",
    "  os.chdir(\"..\")\n",
    "\n",
    "  from IPython.display import HTML\n",
    "  from base64 import b64encode\n",
    "\n",
    "  video_path = './'+CDIR+'/output.mp4'\n",
    "  video_file = genai.upload_file(path=video_path)\n",
    "\n",
    "  import time\n",
    "\n",
    "  while video_file.state.name == \"PROCESSING\":\n",
    "      print('.', end='')\n",
    "      time.sleep(10)\n",
    "      video_file = genai.get_file(video_file.name)\n",
    "\n",
    "  if video_file.state.name == \"FAILED\":\n",
    "    raise ValueError(video_file.state.name)\n",
    "\n",
    "  response = google_model.generate_content([message, video_file], stream=True)\n",
    "  response.resolve()\n",
    "\n",
    "  # genai.delete_file(video_file.name)\n",
    "  return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ko1jueirX1F0"
   },
   "outputs": [],
   "source": [
    "# Store the results in a dict to later save to a file\n",
    "messages = dict()\n",
    "\n",
    "#Store config information in messages\n",
    "messages['s'] = s\n",
    "messages['e'] = e\n",
    "messages['step'] = step\n",
    "messages['max_tokens'] = max_tokens\n",
    "messages['image_resize'] = image_resize\n",
    "messages['s1'] = s1\n",
    "messages['s3'] = s3\n",
    "messages[\"API\"] = API\n",
    "messages['message'] = message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BSUmGbAbLKiq"
   },
   "outputs": [],
   "source": [
    "def write_to_image(messages: dict) -> None:\n",
    "  if not os.path.exists(\"outputs\"):\n",
    "    os.mkdir(\"outputs\")\n",
    "\n",
    "  with open(f\"./outputs/{s}thru{e}with{step}-{API}.txt\", 'w') as output_file:\n",
    "    print(messages, file=output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Vuv15EpehT4E",
    "outputId": "1fdc1b69-9ad7-4581-ef7e-d357820d8a73"
   },
   "outputs": [],
   "source": [
    "# Go thru each, add the prompts to the messages dict\n",
    "for i in range(1):\n",
    "  #Google API\n",
    "  if API == \"GOOGLE\":\n",
    "    for i in range(s, e+1, step): # each of these defined at the top\n",
    "      dir = f\"{i:06d}\"\n",
    "      try:\n",
    "        print(f\"Reading {dir}\")\n",
    "        message = google_prompt_image(dir, image_resize=image_resize, s1=s1, s3=s3)\n",
    "        messages[dir] = message\n",
    "        write_to_image(messages)\n",
    "      except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "  #OpenAI API\n",
    "\n",
    "  if API == \"OPENAI\":\n",
    "    for i in range(s, e+1, step): # each of these defined at the top\n",
    "      dir = f\"{i:06d}\"\n",
    "      try:\n",
    "        print(f\"Reading {dir}\")\n",
    "        #Clear context\n",
    "\n",
    "        message = openai_prompt_image(dir, image_resize=image_resize, s1=s1, s3=s3)\n",
    "        messages[dir] = message\n",
    "        write_to_image(messages)\n",
    "      except Exception as e:\n",
    "        print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xij7GlWNp7Cf",
    "outputId": "6ce3379f-78f5-41ae-d7b4-8631619b78c6"
   },
   "outputs": [],
   "source": [
    "messages"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "llava",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
